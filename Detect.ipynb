{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./einops-0.8.0-py3-none-any.whl\n",
      "einops is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import os\n",
    "path_input = '.'\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy.special import logsumexp\n",
    "!pip install ./einops-0.8.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generated\n",
       "0    1375\n",
       "1       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_train = pd.read_csv(f'{path_input}/llm-detect-ai-generated-text/train_essays.csv')\n",
    "tab_train['set'] = 'train'\n",
    "#tab_train = tab_train.iloc[:12]\n",
    "#tab_daigt = pd.read_csv(f'{path_input}/daigt-v2-train-dataset/train_v2_drcat_02.csv')\n",
    "#tab_daigt.rename(columns = {\"label\":\"generated\"}, inplace=True)\n",
    "#tab_daigt['set'] = 'daigt'\n",
    "#tab_train = pd.concat([tab_train[['text', 'generated', 'set']],\n",
    "#                       tab_daigt[['text', 'generated', 'set']]]).reset_index(drop=True)\n",
    "tab_train['generated'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 torch.float16\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "print(device, dtype, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 torch.float16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916cab0ec8894c4e972125860d65adc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi3.5\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from transformers import CodeGenTokenizer, AutoTokenizer, AutoModelForCausalLM\n",
    "print(device, dtype, flush=True)\n",
    "\n",
    "dict_llm = {\n",
    "   #'gpt2' : ('/kaggle/input/save-models/models/gpt2-xl', GPT2LMHeadModel, 1024, dict()),\n",
    "   #'opt'  : (\"/kaggle/input/save-models/models/facebook/opt-2.7b\", OPTForCausalLM, 2048, dict()),\n",
    "   #'bert' : (\"/kaggle/input/save-models/models/bert-base-uncased\", BertLMHeadModel, 512, {'is_decoder':True}),\n",
    "   # 'phi3.5' : (f'{path_input}/models/Phi-3.5-mini-instruct', AutoModelForCausalLM, 2048,  dict()),\n",
    "   # 'Qwen2.5': (f'{path_input}/models/Qwen2.5-3B-Instruct', AutoModelForCausalLM, 2048,  dict()),\n",
    "   'Qwen2.5': (f'{path_input}/models/Qwen2.5-3B', AutoModelForCausalLM, 2048,  dict()),\n",
    "}\n",
    "\n",
    "llm_tokenizer = dict()\n",
    "llm_model = dict()\n",
    "for _ in dict_llm:\n",
    "    llm_tokenizer[_] = AutoTokenizer.from_pretrained(dict_llm[_][0], add_bos_token = True)\n",
    "    if llm_tokenizer[_].pad_token is None:\n",
    "        llm_tokenizer[_].pad_token = llm_tokenizer[_].eos_token\n",
    "    llm_model[_] = dict_llm[_][1].from_pretrained(dict_llm[_][0], torch_dtype=dtype, device_map=device, **dict_llm[_][3])\n",
    "    print(_, flush=True)\n",
    "\n",
    "print('done', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(input_ids, logits, attention_mask, token_type_ids=None):\n",
    "    with torch.no_grad():\n",
    "        logits = torch.log_softmax(logits.float(), dim=-1)\n",
    "        # scores S, W ,P\n",
    "        tokens = input_ids[:, 1:]\n",
    "        attention_mask = attention_mask[:, 1:]\n",
    "        \n",
    "        entD = torch.sum(logits * torch.exp(logits), dim=-1)[:, 1:]\n",
    "        entL = torch.gather(logits[:, :-1, :], dim=-1, index = tokens[:,:,None])[:,:,0]\n",
    "        \n",
    "        entD = -torch.where(attention_mask!=0, entD, np.nan)\n",
    "        entL = -torch.where(attention_mask!=0, entL, np.nan)\n",
    "        \n",
    "    return entD, entL\n",
    "\n",
    "\n",
    "def generate_logprob(llm_model, llm_tokenizer, prompt, max_length=None, add_special_tokens = True, padding=False):\n",
    "    with torch.no_grad():\n",
    "        device = next(llm_model.parameters()).device\n",
    "        tokens = llm_tokenizer(prompt, return_tensors=\"pt\",\n",
    "                               max_length=max_length, truncation=max_length is not None, truncation_strategy = 'longest_first', add_special_tokens=add_special_tokens, padding=padding)\n",
    "        tokens = {_: tokens[_].to(device) for _ in tokens}\n",
    "        logits = llm_model(**tokens).logits\n",
    "        return compute_entropy(logits=logits, **tokens)\n",
    "\n",
    "\n",
    "class Batch:\n",
    "    def __init__(self, iterable, size=1):\n",
    "        self.iterable = iterable\n",
    "        self.size = size\n",
    "        self.len = len(range(0, len(self.iterable), self.size))\n",
    "        \n",
    "    def __iter__(self):\n",
    "        l = len(self.iterable)\n",
    "        n = self.size\n",
    "        for ndx in range(0, l, n):\n",
    "            yield self.iterable[ndx:min(ndx + n, l)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# feats_list = ['Dmed_Qwen2.5', 'Lmed_Qwen2.5', 'Dp05_Qwen2.5', 'Lstd_Qwen2.5', 'meanchr_Qwen2.5',]\n",
    "feats_list = ['Dmed_phi3.5', 'Lmed_phi3.5', 'Dp05_phi3.5', 'Lstd_phi3.5', 'meanchr_phi3.5',]\n",
    "classifier = OneClassSVM(verbose=1,  kernel='rbf', gamma='auto',nu=0.05);\n",
    "\n",
    "list_op = {\n",
    "    'len':  lambda a, axis: np.sum(np.isfinite(a),axis),\n",
    "    'med': np.nanmedian,\n",
    "    'max': np.nanmax,\n",
    "    'mean': np.nanmean,\n",
    "    'std': np.nanstd,\n",
    "    'p05' : lambda a, axis: np.nanpercentile(a, 5,axis=axis),\n",
    "    'p80' : lambda a, axis: np.nanpercentile(a,80,axis=axis),\n",
    "    'p90' : lambda a, axis: np.nanpercentile(a,90,axis=axis),\n",
    "    'p95' : lambda a, axis: np.nanpercentile(a,95,axis=axis),\n",
    "    'p98' : lambda a, axis: np.nanpercentile(a,98,axis=axis),\n",
    "    #'lse': logsumexp,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "print(batch_size)\n",
    "#for _ in dict_llm:\n",
    "#    print(_, flush=True)\n",
    "#    texts = [' '.join(['hello',]*dict_llm[_][2]) for i in range(batch_size)]\n",
    "#    vet = generate_logprob(llm_model[_], llm_tokenizer[_], texts, max_length=dict_llm[_][2], padding=True).cpu().numpy()\n",
    "#print('done', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(tab):\n",
    "    for index in tqdm.tqdm(tab.index):\n",
    "        text = tab.loc[index,'text']    \n",
    "        tab.loc[index,'len_chr'] = len(text)\n",
    "    for _ in dict_llm:\n",
    "        print(_, flush=True)\n",
    "        for index_list in tqdm.tqdm(Batch(tab.index, batch_size)):\n",
    "            texts = [tab.loc[index,'text'] for index in index_list]\n",
    "            vetD, vetL = generate_logprob(llm_model[_], llm_tokenizer[_], texts, max_length=dict_llm[_][2], padding=True)\n",
    "            vetD = vetD.cpu().numpy()\n",
    "            vetL = vetL.cpu().numpy()\n",
    "            \n",
    "            tab.loc[index_list,'meanchr_'+_] = tab.loc[index_list,'len_chr'].values / np.sum(np.isfinite(vetL),-1)\n",
    "            \n",
    "            for op in list_op:\n",
    "                keyD = 'D'+op+'_'+_\n",
    "                if keyD in feats_list:\n",
    "                    op_vet = list_op[op](vetD, axis=-1)\n",
    "                    for index, value in zip(index_list, op_vet):\n",
    "                        tab.loc[index, keyD] = value\n",
    "                        \n",
    "                keyL = 'L'+op+'_'+_\n",
    "                if keyL in feats_list:\n",
    "                    op_vet = list_op[op](vetL, axis=-1)\n",
    "                    for index, value in zip(index_list, op_vet):\n",
    "                        tab.loc[index, keyL] = value\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1378/1378 [00:00<00:00, 4370.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi3.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/345 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n",
      "100%|██████████| 345/345 [02:18<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'prompt_id', 'text', 'generated', 'set', 'len_chr',\n",
      "       'meanchr_phi3.5', 'Dmed_phi3.5', 'Lmed_phi3.5', 'Lstd_phi3.5',\n",
      "       'Dp05_phi3.5'],\n",
      "      dtype='object')\n",
      "done training feature extraction\n",
      "[LibSVM]done training\n",
      "[[2.24123584 1.61412471 0.07470961 2.69123403 4.35443439]] [[0.30619368 0.32547955 0.06760257 0.18549875 0.22942455]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n",
      "optimization finished, #iter = 177\n",
      "obj = 150.050253, rho = 4.968066\n",
      "nSV = 86, nBSV = 51\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    tab_train = feature_extraction(tab_train)\n",
    "    print(tab_train.columns)\n",
    "    print('done training feature extraction', flush=True)\n",
    "\n",
    "    train_feats = tab_train[tab_train['generated']==0][feats_list].values\n",
    "    z_mean = np.mean(train_feats, 0, keepdims=True)\n",
    "    z_std  = np.maximum(np.std(train_feats, 0, keepdims=True), 1e-4)\n",
    "\n",
    "    classifier.fit((train_feats - z_mean)/z_std)\n",
    "    \n",
    "    print('done training', flush=True)\n",
    "    \n",
    "else:\n",
    "    pass\n",
    "\n",
    "print(z_mean, z_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 827.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi3.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done test feature extraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tab_test = pd.read_csv(f'{path_input}/llm-detect-ai-generated-text/test_essays.csv')\n",
    "tab_test = feature_extraction(tab_test)\n",
    "print('done test feature extraction', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feats = tab_test[feats_list].values\n",
    "tab_test['generated'] = -1.0*classifier.decision_function((test_feats - z_mean)/z_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>4.967997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>4.968066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>4.968066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa   4.967997\n",
       "1  1111bbbb   4.968066\n",
       "2  2222cccc   4.968066"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = tab_test[['id','generated']]\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "pd.read_csv(\"./submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jjver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
